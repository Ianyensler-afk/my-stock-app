import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objs as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import feedparser
import urllib.parse
import time
import requests

# --- 1. è¨­å®šé é¢ ---
st.set_page_config(page_title="å°è‚¡æˆ°æƒ…å®¤ V21.0 (æŠ—å´©æ½°ç‰ˆ)", layout="wide")
st.title("ğŸ“ˆ å°è‚¡ AI æŠ•è³‡æ±ºç­–ç³»çµ± (å®‰å…¨æ°£å›Šç‰ˆ)")

# --- 2. å´é‚Šæ¬„ ---
st.sidebar.header("ğŸ” æŸ¥è©¢åƒæ•¸")
ticker_input = st.sidebar.text_input("è‚¡ç¥¨ä»£è™Ÿ:", "2330")
date_range = st.sidebar.select_slider("è³‡æ–™å€é–“", options=["3mo", "6mo", "1y", "2y", "5y"], value="1y")
initial_capital = st.sidebar.number_input("å›æ¸¬åˆå§‹è³‡é‡‘ (å…ƒ)", value=100000)

def format_ticker(symbol):
    symbol = symbol.strip()
    if symbol.isdigit(): return f"{symbol}.TW"
    return symbol.upper()

stock_id = format_ticker(ticker_input)
clean_id = stock_id.split('.')[0]

# --- 3. Goodinfo çˆ¬èŸ² ---
@st.cache_data(ttl=3600)
def get_goodinfo_data(stock_id_num):
    url = f"https://goodinfo.tw/tw/StockBzPerformance.asp?STOCK_ID={stock_id_num}"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/114.0.0.0 Safari/537.36", "Referer": url}
    try:
        res = requests.get(url, headers=headers, timeout=5) # timeout æ”¹çŸ­ä¸€é»ï¼Œé¿å…å¡æ­»
        res.encoding = "utf-8"
        dfs = pd.read_html(res.text)
        target_df = None
        for df in dfs:
            flat_cols = [''.join(str(c) for c in col) for col in df.columns] if isinstance(df.columns, pd.MultiIndex) else df.columns
            if any("EPS" in str(c) for c in flat_cols): target_df = df; target_df.columns = flat_cols; break
        
        if target_df is None: return None
        cols = target_df.columns
        eps_c = next((c for c in cols if "EPS" in c and "å…ƒ" in c), None)
        roe_c = next((c for c in cols if "ROE" in c), None)
        yield_c = next((c for c in cols if "æ®–åˆ©ç‡" in c), None)
        pe_c = next((c for c in cols if "æœ¬ç›Šæ¯”" in c), None)
        
        def parse(v):
            try: return float(v)
            except: return 0.0

        return {
            "EPS": parse(target_df[eps_c].iloc[0]) if eps_c else 0,
            "ROE": parse(target_df[roe_c].iloc[0]) if roe_c else 0,
            "Yield": parse(target_df[yield_c].iloc[0]) if yield_c else 0,
            "PER": parse(target_df[pe_c].iloc[0]) if pe_c else 0
        }
    except: return None

# --- 4. [ä¿®å¾©é‡é»] å®‰å…¨ç²å– YFinance è³‡æ–™ ---
@st.cache_data(ttl=300) # åŠ ä¸Šå¿«å–ï¼Œæ¸›å°‘å° Yahoo çš„è«‹æ±‚é »ç‡
def load_data_safe(symbol, period):
    try:
        # å˜—è©¦æŠ“å–
        data = yf.Ticker(symbol).history(period=period)
        
        # å®¹éŒ¯å˜—è©¦
        if data.empty:
            if ".TW" in symbol: data = yf.Ticker(symbol.replace(".TW", "")).history(period=period)
            else: data = yf.Ticker(f"{symbol}.TW").history(period=period)
            
        if data.empty: return None
        
        data.reset_index(inplace=True)
        data['Date'] = pd.to_datetime(data['Date']).dt.tz_localize(None)
        data.dropna(subset=['Close'], inplace=True)
        return data
    except Exception as e:
        # é€™è£¡æœƒæ•æ‰ Rate Limit éŒ¯èª¤ï¼Œå›å‚³ None è€Œä¸æ˜¯è®“ç¨‹å¼å´©æ½°
        print(f"Yahoo Data Error: {e}")
        return None

# [æ–°å¢] å®‰å…¨ç²å–åŸºæœ¬é¢ Infoï¼Œé¿å… info å±¬æ€§å ±éŒ¯
def get_stock_info_safe(symbol):
    try:
        ticker = yf.Ticker(symbol)
        # é€™è£¡æœ€å®¹æ˜“è§¸ç™¼ RateLimitErrorï¼Œæ‰€ä»¥ä¸€å®šè¦åŒ…èµ·ä¾†
        return ticker.info
    except Exception:
        return {} # å¤±æ•—å°±å›å‚³ç©ºå­—å…¸ï¼Œç¨‹å¼ç¹¼çºŒè·‘

def calculate_indicators(df):
    df['MA5'] = df['Close'].rolling(5).mean()
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA60'] = df['Close'].rolling(60).mean()
    
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)
    rs = gain.ewm(alpha=1/14, adjust=False).mean() / loss.ewm(alpha=1/14, adjust=False).mean()
    df['RSI'] = 100 - (100 / (1 + rs))
    
    exp12 = df['Close'].ewm(span=12, adjust=False).mean()
    exp26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp12 - exp26
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['Hist'] = df['MACD'] - df['Signal']
    
    low_min = df['Low'].rolling(9).min()
    high_max = df['High'].rolling(9).max()
    rsv = (df['Close'] - low_min) / (high_max - low_min) * 100
    rsv = rsv.fillna(50)
    k, d = [50], [50]
    for i in range(1, len(rsv)):
        k.append(k[-1]*2/3 + rsv.iloc[i]/3)
        d.append(d[-1]*2/3 + k[-1]/3)
    df['K'] = k; df['D'] = d
    return df

def calculate_support_resistance(df, window=60):
    recent = df[-window:]
    return recent['Low'].min(), recent['High'].max()

def analyze_16_patterns(df):
    if len(df) < 3: return "è³‡æ–™ä¸è¶³", "ç„¡æ³•åˆ¤æ–·", 0
    t0 = df.iloc[-1]; t1 = df.iloc[-2]; t2 = df.iloc[-3]
    
    def get_body(row): return abs(row['Close'] - row['Open'])
    def get_upper(row): return row['High'] - max(row['Open'], row['Close'])
    def get_lower(row): return min(row['Open'], row['Close']) - row['Low']
    def is_red(row): return row['Close'] > row['Open']
    def is_black(row): return row['Close'] < row['Open']
    def body_ratio(row): return get_body(row) / (row['High'] - row['Low'] + 0.001)
    
    is_downtrend = t0['Close'] < t0['MA20']
    
    # ç°¡åŒ–ç‰ˆåˆ¤æ–·é‚è¼¯ï¼Œé¿å…éé•·
    if body_ratio(t0) < 0.1:
        if get_upper(t0) > 0.6*(t0['High']-t0['Low']): return "å¢“ç¢‘ç·š", "âŒ é‡å£“æ”¶ä½ï¼Œå¼·çƒˆçœ‹ç©º", -2
        if get_lower(t0) > 0.6*(t0['High']-t0['Low']): return "èœ»èœ“ç·š", "âœ… æ”¯æ’å¼·å‹ï¼Œå¼·çƒˆçœ‹å¤š", 2
        return "åå­—ç·š", "âš ï¸ å¤šç©ºåƒµæŒï¼Œè®Šç›¤å‰å…†", 0
    
    if body_ratio(t0) > 0.8:
        if is_red(t0): return "å¤§é™½ç·š", "ğŸ”¥ è²·ç›¤å¼·å‹ï¼Œè¶¨å‹¢çœ‹æ¼²", 2
        else: return "å¤§é™°ç·š", "ğŸ’§ è³£å£“æ²‰é‡ï¼Œè¶¨å‹¢çœ‹è·Œ", -2
        
    return "ä¸€èˆ¬éœ‡ç›ª", "ç„¡ç‰¹æ®Šå‹æ…‹", 0

# --- æ–°è ---
def get_enhanced_news(clean_id, clean_name):
    queries = [f"{clean_id} {clean_name}", f"{clean_name} è‚¡åƒ¹"]
    all_news = []
    seen = set()
    blacklist = ["NBA","MLB","è·æ£’","ç±ƒçƒ","å•¦å•¦éšŠ","è—äºº","ç·‹è","æ¼”å”±æœƒ","å½©åˆ¸"]
    for q in queries:
        encoded = urllib.parse.quote(q)
        feed = feedparser.parse(f"https://news.google.com/rss/search?q={encoded}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant")
        for entry in feed.entries:
            if entry.link in seen: continue
            if any(x in entry.title for x in blacklist): continue
            all_news.append(entry)
            seen.add(entry.link)
    all_news.sort(key=lambda x: x.published_parsed if x.get('published_parsed') else time.localtime(0), reverse=True)
    return all_news

# --- å›æ¸¬ ---
def run_backtest(df, fund):
    capital = fund; position = 0; history = []
    for i in range(1, len(df)):
        p = df['Close'].iloc[i]; d = df['Date'].iloc[i]; ma20 = df['MA20'].iloc[i]
        macd_gold = df['MACD'].iloc[i-1] < df['Signal'].iloc[i-1] and df['MACD'].iloc[i] > df['Signal'].iloc[i]
        kdj_gold = df['K'].iloc[i-1] < df['D'].iloc[i-1] and df['K'].iloc[i] > df['D'].iloc[i] and df['K'].iloc[i] < 50
        trend_up = p > ma20
        if position == 0 and trend_up and (macd_gold or kdj_gold):
            position = capital / p; capital = 0
            history.append(f"ğŸ”´ {d.strftime('%Y-%m-%d')} è²·é€² @ {p:.2f}")
        elif position > 0 and p < ma20:
            capital = position * p; position = 0
            history.append(f"ğŸŸ¢ {d.strftime('%Y-%m-%d')} è³£å‡º @ {p:.2f}")
    final = capital if position == 0 else position * df['Close'].iloc[-1]
    return final, history

# --- ä¸»ç¨‹å¼ ---
# [é‡è¦ä¿®æ”¹] ä½¿ç”¨ Safe ç‰ˆå‡½æ•¸ï¼Œé€™è£¡ä¸æœƒå´©æ½°ï¼Œåªæœƒå›å‚³ None
data = load_data_safe(stock_id, date_range)

if data is not None and not data.empty:
    data = calculate_indicators(data)
    
    # [é‡è¦ä¿®æ”¹] ä½¿ç”¨ Safe ç‰ˆ Infoï¼Œå¦‚æœ Yahoo é– IPï¼Œé€™è£¡æœƒæ‹¿åˆ°ç©ºå­—å…¸ {}
    info = get_stock_info_safe(stock_id) 
    
    # å®¹éŒ¯è™•ç†ï¼šå¦‚æœ info æ˜¯ç©ºçš„ï¼Œå°±çµ¦é è¨­å€¼
    name = info.get('longName', stock_id) if info else stock_id
    clean_name = name.split(' ')[0]
    
    # Goodinfo çˆ¬èŸ²
    try: goodinfo_data = get_goodinfo_data(clean_id)
    except: goodinfo_data = None
    
    # æ•¸æ“šæ•´åˆ (Yahoo å¤±æ•—å°±å…¨é  Goodinfo)
    if goodinfo_data:
        eps = goodinfo_data['EPS']; roe = goodinfo_data['ROE']; dy = goodinfo_data['Yield']; per = goodinfo_data['PER']
        src_tag = "âœ… æ•¸æ“šä¾†æº: Goodinfo (Yahooè¢«é™æµï¼Œå·²è‡ªå‹•åˆ‡æ›)"
    else:
        # å¦‚æœ Yahoo Info ä¹Ÿè¢«é–ï¼Œé€™äº›éƒ½æœƒæ˜¯ 0
        eps = info.get('trailingEps', 0) if info else 0
        roe = (info.get('returnOnEquity', 0) or 0)*100 if info else 0
        dy = (info.get('dividendYield', 0) or 0)*100 if info else 0
        per = info.get('trailingPE', 0) if info else 0
        src_tag = "âš ï¸ æ•¸æ“šä¾†æº: Yahoo (è‹¥æ•¸æ“šç‚º0ä»£è¡¨è¢«é™æµ)"

    # æ¼²è·Œå¹…
    curr_p = data['Close'].iloc[-1]
    prev_p = data['Close'].iloc[-2]
    change = curr_p - prev_p
    pct_change = (change / prev_p) * 100
    
    # ç›®æ¨™åƒ¹
    target_low = eps * 15; target_high = eps * 22
    if target_low < 0: target_low = 0; target_high = 0
    
    st.subheader(f"{name} ({stock_id})")
    st.caption(src_tag)
    
    col_k1, col_k2, col_k3, col_k4, col_k5 = st.columns(5)
    col_k1.metric("è‚¡åƒ¹", f"{curr_p:.2f}", f"{change:.2f} ({pct_change:.2f}%)")
    col_k2.metric("EPS", f"{eps:.2f}å…ƒ")
    supp, res = calculate_support_resistance(data)
    col_k3.metric("å£“åŠ›", f"{res:.2f}")
    col_k4.metric("æ”¯æ’", f"{supp:.2f}")
    with col_k5:
        st.metric("ä¼°ç®—ç›®æ¨™å€é–“", f"{target_low:.0f} - {target_high:.0f}")
        st.link_button("ğŸ” æœåˆ¸å•†å ±å‘Š", f"https://www.google.com/search?q={clean_name}+{clean_id}+ç›®æ¨™åƒ¹+åˆ¸å•†+å ±å‘Š")

    st.divider()
    
    # AI è¨ºæ–·
    last = data.iloc[-1]
    score = 0; reasons = []
    
    k_name, k_meaning, k_score = analyze_16_patterns(data)
    score += k_score
    reasons.append(f"ğŸ•¯ï¸ [å‹æ…‹] **{k_name}**ï¼š{k_meaning}")
    
    if curr_p > last['MA20']: score += 2; reasons.append("âœ… [è¶¨å‹¢] ç«™ä¸Šæœˆç·š +2")
    else: score -= 2; reasons.append("ğŸ”» è·Œç ´æœˆç·š -2")
    if last['MACD'] > last['Signal']: score += 2; reasons.append("âœ… [å‹•èƒ½] MACDé‡‘å‰ +2")
    else: score -= 2; reasons.append("ğŸ”» [å‹•èƒ½] MACDæ­»å‰ -2")
    if last['K'] > last['D']: score += 1; reasons.append("âœ… [æ³¢æ®µ] KDJé‡‘å‰ +1")
    else: score -= 1; reasons.append("ğŸ”» [æ³¢æ®µ] KDJæ­»å‰ -1")
    if eps > 0: score += 1; reasons.append("âœ… [åŸºæœ¬] EPSç²åˆ© +1")
    else: score -= 1; reasons.append("ğŸ”» [åŸºæœ¬] EPSè™§æ -1")
    
    bg = "#d4edda" if score >= 4 else "#f8d7da" if score <= -4 else "#fff3cd"
    sugg = "å¼·çƒˆè²·é€² ğŸš€" if score >= 4 else "å¼·çƒˆè³£å‡º ğŸ»" if score <= -4 else "è§€æœ›"
    
    st.markdown(f"""<div style="background-color: {bg}; padding: 15px; border-radius: 10px;">
        <h3>ğŸ¤– AI è¨ºæ–·: {sugg} (ç¸½åˆ†: {score})</h3>
        <ul style="margin-top:10px;">
            {''.join([f'<li style="margin-bottom:5px;">{r}</li>' for r in reasons])}
        </ul>
    </div>""", unsafe_allow_html=True)
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š å…¨èƒ½åœ–è¡¨", "ğŸ’° ç­–ç•¥å›æ¸¬", "ğŸ¢ è²¡å ±è©³æƒ…", "ğŸ•µï¸ ç±Œç¢¼é¢", "ğŸ“° æ–°è"])
    
    with tab1:
        data['DateStr'] = data['Date'].dt.strftime('%Y-%m-%d')
        fig = make_subplots(rows=4, cols=1, shared_xaxes=True, row_heights=[0.4, 0.2, 0.2, 0.2], vertical_spacing=0.03)
        fig.add_trace(go.Candlestick(x=data['DateStr'], open=data['Open'], high=data['High'], low=data['Low'], close=data['Close'], name='Kç·š'), row=1, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['MA20'], line=dict(color='blue'), name='MA20'), row=1, col=1)
        fig.add_hline(y=res, line_dash="dot", line_color="red", row=1, col=1)
        fig.add_hline(y=supp, line_dash="dot", line_color="green", row=1, col=1)
        clrs = ['red' if v < 0 else 'green' for v in data['Hist']]
        fig.add_trace(go.Bar(x=data['DateStr'], y=data['Hist'], marker_color=clrs, name='MACD'), row=2, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['MACD'], line=dict(color='black'), name='DIF'), row=2, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['Signal'], line=dict(color='red'), name='DEM'), row=2, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['K'], line=dict(color='orange'), name='K'), row=3, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['D'], line=dict(color='blue'), name='D'), row=3, col=1)
        fig.add_trace(go.Scatter(x=data['DateStr'], y=data['RSI'], line=dict(color='purple'), name='RSI'), row=4, col=1)
        fig.add_hline(y=70, line_dash="dash", line_color="red", row=4, col=1)
        fig.add_hline(y=30, line_dash="dash", line_color="green", row=4, col=1)
        fig.update_xaxes(type='category', tickmode='auto', nticks=20) 
        fig.update_layout(height=900, showlegend=False, margin=dict(t=10, b=10, l=10, r=10))
        st.plotly_chart(fig, use_container_width=True)

    with tab2:
        final_val, trade_log = run_backtest(data, initial_capital)
        ret = (final_val - initial_capital)/initial_capital * 100
        st.metric("ç­–ç•¥å›å ±", f"{ret:.2f}%")
        with st.expander("äº¤æ˜“æ˜ç´°", expanded=True):
            if trade_log:
                for log in trade_log: st.markdown(log)
            else: st.info("ç„¡äº¤æ˜“è¨Šè™Ÿ")

    with tab3:
        if goodinfo_data:
            st.success("Goodinfo æ•¸æ“šæŠ“å–æˆåŠŸ")
            st.json(goodinfo_data)
        else:
            st.warning("Yahoo Finance é™æµä¸­ï¼Œä¸” Goodinfo å‚™æ´å¤±æ•—ã€‚å»ºè­°ç¨å¾Œå†è©¦ã€‚")
            st.link_button("å‰å¾€ Goodinfo", f"https://goodinfo.tw/tw/StockBzPerformance.asp?STOCK_ID={clean_id}")

    with tab4:
        c1, c2, c3 = st.columns(3)
        with c1: st.link_button("ä¸‰å¤§æ³•äºº (ç©è‚¡ç¶²)", f"https://www.wantgoo.com/stock/{clean_id}/institutional-investors")
        with c2: st.link_button("ä¸»åŠ›é€²å‡º (ç©è‚¡ç¶²)", f"https://www.wantgoo.com/stock/{clean_id}/major-investors")
        with c3: st.link_button("ç±Œç¢¼Kç·š (Goodinfo)", f"https://goodinfo.tw/tw/ShowK_Chart.asp?STOCK_ID={clean_id}&CHT_CAT=DATE")

    with tab5:
        news = get_enhanced_news(clean_id, clean_name)
        if news:
            for n in news[:30]:
                try: t_str = datetime(*n.published_parsed[:6]).strftime('%m-%d %H:%M')
                except: t_str = "Recent"
                st.markdown(f"**{t_str}** [{n.title}]({n.link})")
                st.divider()
        else: st.info("ç„¡æ–°è")
        st.link_button("ğŸ” å» Google æœå°‹æ›´å¤š", f"https://www.google.com/search?q={clean_name}+æ–°è")

else:
    # é€™è£¡é¡¯ç¤ºçµ¦ç”¨æˆ¶çœ‹ï¼Œè®“ä»–å€‘çŸ¥é“ç‚ºä»€éº¼ç¾åœ¨æ²’ç•«é¢
    st.error("âš ï¸ ä¼ºæœå™¨å¿™ç¢Œä¸­ (Yahoo Finance é™æµ)")
    st.info("ç”±æ–¼é›²ç«¯ä¸»æ©Ÿå…±ç”¨ IPï¼ŒYahoo æš«æ™‚é˜»æ“‹äº†é€£ç·šã€‚è«‹å˜—è©¦ï¼š\n1. ç­‰å¾… 5~10 åˆ†é˜å¾Œé‡æ–°æ•´ç†ã€‚\n2. æ™šé»å†è©¦ã€‚") #streamlit run app.py
